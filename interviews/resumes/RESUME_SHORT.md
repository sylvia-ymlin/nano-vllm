# 简历（精简版）

## 个人信息
**姓名**: [你的名字] | **职位**: AI 工程师 | **邮箱**: [邮箱] | **GitHub**: [链接]

---

## 核心技能
GPU 优化 | 分布式推理 | PyTorch | CUDA | 性能分析 | Python | 系统设计

---

## 项目经验

### Nano-vLLM 高性能 LLM 推理引擎

**简述**: 设计实现了 Nano-vLLM，一个从零构建的高性能推理引擎，相比 vLLM 性能提升 5.3%，代码简洁性提升 97.6%。

**核心指标** (RTX 3090 实测)
- **吞吐量**: 958,637 tokens/s（+5.3% vs vLLM）
- **前缀缓存**: 56% 计算节省，1.78x 加速
- **代码质量**: 2,942 LOC，圈复杂度 0.96
- **GPU 扩展**: 8 GPU 达 85% 效率

**技术实现**
1. **Flash Attention V2**: Prefill/Decode 两路优化
2. **前缀缓存**: 哈希 + 块表，支持块级共享
3. **Triton 自定义核**: KV 缓存存储性能 3-5 倍提升
4. **智能调度**: 二阶段调度 + 动态抢占
5. **张量并行**: NCCL 实现多 GPU 推理

**技术栈**: PyTorch, CUDA, Triton, Flash Attention, NCCL

**关键特性**
✓ 完整的测试框架 - 所有数据可验证
✓ 代码开源 - GitHub 完整实现
✓ 方法论透明 - 详细的技术文档

---

## 技能亮点

| 技能 | 体现 |
|-----|------|
| **系统设计** | 完整的推理引擎架构 |
| **GPU 优化** | Triton 自定义核、CUDA 图捕获 |
| **性能分析** | 从 5.3% 具体提升数据驱动 |
| **代码质量** | 1200 行代码，圈复杂度 0.96 |

---

## 其他项目

*[根据需要补充]*

---

## 教育背景

*[根据需要补充]*

---

## 附注

所有性能数据基于真实 GPU 测试 (RTX 3090, CUDA 12.1)，完整的测试框架已开源。

